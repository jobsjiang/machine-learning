{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mp.weixin.qq.com/s/VDvkSraPs-OEvGevMWkwgw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import glob,json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self,img_path,img_label,transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label\n",
    "        self.transform = transform\n",
    "    def __getitem__(self,index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB') # 读取数据\n",
    "        img = self.transform(img) # 做相应变换\n",
    "        if self.img_label:\n",
    "            lbl = np.array(self.img_label[index],dtype=np.int) # 制作标签\n",
    "            lbl = list(lbl) + (5-len(lbl))*[10] # 标签长度小于5的用10进行填充\n",
    "            return img,torch.from_numpy(np.array(lbl[:5]))\n",
    "        else:\n",
    "            return img\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "# 定义模型\n",
    "class SVHN_Model(nn.Module):\n",
    "    def __init__(self)\n",
    "        super(SVHN_Model,self).__init__()\n",
    "        self.cnn = models.resnet50(pretrained=True) # 加载resnet50\n",
    "        self.cnn.avgpool = nn.AdaptiveAvgPool2d(1) # 将平均池化改为自适应平均池化\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1]) # 去除最后的线性层\n",
    "        self.fc1 = nn.Linear(2048,11)\n",
    "        self.fc2 = nn.Linear(2048,11)\n",
    "        self.fc3 = nn.Linear(2048,11)\n",
    "        self.fc4 = nn.Linear(2048,11)\n",
    "        self.fc5 = nn.Linear(2048,11)\n",
    "    def forward(self,img):\n",
    "        feat = self.cnn(img)\n",
    "        feat = feat.view(feat.shape[0],-1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        return c1,c2,c3,c4,c5\n",
    "def train(train_loader,model,criterion,optimizer):\n",
    "    model.train() # 切换模型为训练模式\n",
    "    train_loss = []\n",
    "    for input,target in tqdm(train_loader): # 取出数据与对应标签\n",
    "        if use_cuda:\n",
    "            input,target = input.cuda(),target.cuda()\n",
    "        target = target.long()\n",
    "        c0, c1, c2, c3, c4 = model(input) # 得到预测值\n",
    "        loss = criterion(c0, target[:, 0]) + criterion(c1, target[:, 1]) + \\\n",
    "                criterion(c2, target[:, 2]) + criterion(c3, target[:, 3]) + \\\n",
    "                criterion(c4, target[:, 4]) # 计算loss\n",
    "        optimizer.zero_grad() # 梯度清零\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 参数更新\n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "def predict(test_loader,model):\n",
    "    model.eval() # 切换模型为预测模型\n",
    "    with torch.no_grad(): # 不记录模型梯度信息\n",
    "        for input in tqdm(test_loader):\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "            c0, c1, c2, c3, c4 = model(input)\n",
    "            if use_cuda:\n",
    "                output = np.concatenate([\n",
    "                    c0.data.cpu().numpy(), c1.data.cpu().numpy(), c2.data.cpu().numpy(), # 将结果水平合并，即第一个字符索引为第一列到第十一列，\n",
    "                    c3.data.cpu().numpy(), c4.data.cpu().numpy()], axis=1)               # 第二个字符为第十二列到第二十二列，依次往下\n",
    "            else:\n",
    "                 output = np.concatenate([\n",
    "                        c0.data.numpy(), c1.data.numpy(), c2.data.numpy(), \n",
    "                        c3.data.numpy(), c4.data.numpy()], axis=1)\n",
    "            test_pred.append(output)\n",
    "        test_pred = np.vstack(test_pred)\n",
    "    return test_pred\n",
    "train_path = glob.glob('../../dataset/mchar/mchar_train/*.png') \n",
    "test_path = glob.glob('../../dataset/mchar/mchar_test_a/*.png')\n",
    "train_path.sort()\n",
    "test_path.sort()\n",
    "train_json = json.load(open('../../dataset/mchar/mchar_train.json')) # 读取训练集标注文件\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "trans_fun = transforms.Compose([\n",
    "    transforms.Resize((64,128)),# 将图片裁剪为64*128\n",
    "    transforms.ToTensor(),# 转为Tensor\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 标准化\n",
    "])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(train_path,[],trans_fun),\n",
    "    batch_size=40,\n",
    "    shuffle=False\n",
    ")\n",
    "model = SVHN_Model()\n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(),0.001) # Adam优化器\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "for epoch in range(10):\n",
    "    train_loss = train(train_loader, model, criterion, optimizer) # 训练\n",
    "    print(epoch, train_loss)    \n",
    "test_predict_label = predict(test_loader, model)\n",
    "test_predict_label = np.vstack([\n",
    "    test_predict_label[:, :11].argmax(1), test_predict_label[:, 11:22].argmax(1),\n",
    "    test_predict_label[:, 22:33].argmax(1), test_predict_label[:, 33:44].argmax(1),\n",
    "    test_predict_label[:, 44:55].argmax(1),\n",
    "]).T\n",
    "\n",
    "test_label_pred = []\n",
    "for x in test_predict_label:\n",
    "    test_label_pred.append(''.join(map(str, x[x!=10]))) # 取出预字符不为10的字符且顺序排列\n",
    "\n",
    "df_submit = pd.read_csv('../input/sample_submit_A.csv')\n",
    "df_submit['file_code'] = test_label_pred\n",
    "df_submit.to_csv('submit.csv', index=None) # 保存结果文件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
