{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化，返回值为缩放到[0,1]区间的数据\n",
    "MinMaxScalerin().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化，返回值为标准化后的数据\n",
    "StandardScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 过滤法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方差过滤法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方差选择法，返回值为特征选择后的数据  参数threshold为方差的阈值\n",
    "VarianceThreshold(threshold=3).fit_transform(data)\n",
    "# 使用get_support方法，得到选择特征列的序号\n",
    "VarianceThreshold(threshold=3).get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相关系数过滤法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from scipy.stats import pearsonr\n",
    "# 选择K个最好的特征，返回选择特征后的数据\n",
    "# 第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。在此定义为计算相关系数\n",
    "# 参数k为选择的特征个数\n",
    "\n",
    "SelectKBest(lambda X, Y: array(map(lambda x: pearsonr(x, Y), X.T)).T,\n",
    "            k=2).fit_transform(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卡方值过滤法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "#选择K个最好的特征，返回选择特征后的数据\n",
    "SelectKBest(chi2,k=2).fit_transform(data,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 互信息过滤法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from minepy import MINE\n",
    "#由于MINE的设计不是函数式的，定义mic方法将其为函数式的，返回一个二元组的第二项设置成固定的P值为0.5\n",
    "def mic(x,y):\n",
    "    m = MINE()x = np.random.uniform(-1, 1, 10000)\n",
    "    m.compute_score(x, x**2)\n",
    "    printm.mic()\n",
    "#选择k个最好的特征，返回特征选择后的数据\n",
    "SelectKBest(lamda X,Y:array(map(lamda x:mic(x,y),X.T)).T,k=2).fit_transform(data,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Wrapper 包装法 是一种寻找最优特征子集的贪心算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "递归特征消除法RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#递归特征消除法，返回特征选择后的数据\n",
    "#参数n_features_to_select为选择的特征个数\n",
    "#参数estimator为基模型\n",
    "RFE(estimator=LogisticRegression(),n_features_to_select=2).fit_transform(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las Vegas Wrapper（LVW）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于惩罚项的特征选择法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "#利用L1正则项，LinerSVC选择特征\n",
    "#参数C控制特征稀疏程度\n",
    "#SVM,logistic-regression，参数c控制稀疏程度，参数c越小，越少的特征被选中。\n",
    "Lasso中，参数alpha越大越少的特征被选中。\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python使用feature_selection库的SelectFromModel类结合带L1惩罚项的逻辑回归模型来选择特征\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#利用L1正则项，LogisticRegression选择特征\n",
    "#参数C控制特征稀疏程度\n",
    "SelectFromModel(LogisticRegression(penalty=\"l1\", C=0.1)).fit_transform(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于树模型的特征选择法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#GBDT作为基模型的特征选择\n",
    "SelectFromModel(GradientBoostingClassifier()).fit_transform(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
