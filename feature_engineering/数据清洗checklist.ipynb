{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mp.weixin.qq.com/s?__biz=MzIwOTc2MTUyMg==&mid=2247510058&idx=4&sn=b813178d6f696e370070cf43eececb93&chksm=976c0db7a01b84a14e2e3a307d59f0c749da14c70325ba8e491d923e8cd6613275c03b3ffc92&scene=126&sessionid=1606788985&key=6ef8794b749be73569f5cf9065fa389f99c283523eeec404195d4844d6ef193d8d07216ed4c0761477a5c054aeecaa507abbf46d8255b5698249d7e6999640b1ec17187d767ccfac6498a185f06da6adb03cef4998c362a65cd0cd090fce144029e0de5232475282601c59bc6c134352f9dbf39379075ad4904bff39f0b3728f&ascene=1&uin=MjA1MjAyODkxNg%3D%3D&devicetype=Windows+10+x64&version=6300002f&lang=zh_CN&exportkey=Acn8pNN7JwxqrhTmfs6QAG0%3D&pass_ticket=NzkU2cE8LYsV2rsLelZKP70AyJsxIFm%2FiA0sYCDcaYxuj0aUG7LILDD87lbmM9%2F%2F&wx_header=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.启动阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示当前工作路径\n",
    "os.getcwd()\n",
    "# 罗列当前路径下的所有文件\n",
    "os.listdir()\n",
    "# 改变工作目录\n",
    "os.chdir(\"/PATH/TO/SAMSHARE\")\n",
    "# 初始化基础目录\n",
    "data_path = './02_data/'\n",
    "save_path = './03_model/'\n",
    "output_path = './04_output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取csv文件\n",
    "data = pd.read_csv(data_path + \"data.csv\",encoding='utf8') # 有时候用gbk\n",
    "# 读取txt文件\n",
    "data = pd.read_csv(data_path + 'data.txt',sep='\\t',encoding='utf8') # 有时候用gbk\n",
    "# 读取excel文件\n",
    "data = pd.read_excel(data_path + 'data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.数据结构初探"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看DataFrame每个字段的空值情况，数据类型\n",
    "df.info()\n",
    "# 查看DataFrame的形状\n",
    "df.shape\n",
    "# 查看DataFrame的列名\n",
    "df.columns\n",
    "# 查看字段的枚举值数量\n",
    "df[\"type\"].nunique()\n",
    "# 查看字段的枚举值\n",
    "df[\"type\"].unique()\n",
    "# 查看字段的枚举值统计\n",
    "df[\"species\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.数据空值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看空值占比\n",
    "df.isnull().sum()*100/len(df)\n",
    "\n",
    "## 丢弃与空值相关的数据 ##\n",
    "#######################\n",
    "# 删除所有包含空值的行\n",
    "df.dropna()\n",
    "\n",
    "# 删除所有包含空值的列\n",
    "df.dropna(axis=1)\n",
    "\n",
    "# 删除全部为空值的列\n",
    "df.dropna(axis=1, how='all')\n",
    "## 特殊值替代空值 ##\n",
    "##################\n",
    "# 空值全部填充为0\n",
    "df.fillna(0)\n",
    "\n",
    "# 修改指定位置的值\n",
    "df.at[1, \"sepal_length\"]= 9999\n",
    "\n",
    "# 用字符串替代空值\n",
    "df.fillna(\"data missing\")\n",
    "\n",
    "# 用均值填充\n",
    "df.fillna(df.mean())\n",
    "\n",
    "# 用指定列的均值来填充指定列\n",
    "df[\"sepal_length\"].fillna(df[\"sepal_length\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.基础列操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过列名选择指定“单列”\n",
    "df[\"sepal_length\"]\n",
    "\n",
    "# 通过列名选择指定“多列”\n",
    "df[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"spp\"]]\n",
    "\n",
    "# 通过数字选择指定列（需要连续）\n",
    "df.iloc[:, 2:4]\n",
    "\n",
    "# 通过数字选择指定列（不需要连续）\n",
    "df.iloc[:, [1,3,4]]\n",
    "\n",
    "# 丢弃某列\n",
    "df.drop(\"sepal_length\", axis=1)\n",
    "\n",
    "# 添加新列\n",
    "df['new'] = df[\"sepal_length\"]*2\n",
    "\n",
    "# 条件判断生成新列\n",
    "df['newcol'] = [\"short\" if i<3 else \"long\" for i in df[\"sepal_width\"]] \n",
    "\n",
    "# 枚举值映射转换\n",
    "df.replace({\"Species\":{\"setosa\":1, \"versicolor\":2, \"virginica\":3}})\n",
    "\n",
    "# 计算指定两列的均值\n",
    "df[[\"sepal_length\", \"sepal_width\"]].mean()\n",
    "\n",
    "# 同时计算指定两列的加总和均值\n",
    "df[[\"sepal_length\", \"sepal_width\"]].agg([np.sum, np.mean])\n",
    "\n",
    "# 转置DataFrame\n",
    "df.T\n",
    "\n",
    "# 把列名转成List\n",
    "df.columns.tolist()\n",
    "\n",
    "# 排序\n",
    "df.sort_values(by = \"sepal_width\", ascending = True)\n",
    "\n",
    "# 改列名\n",
    "df.rename(columns={\"old_name\": \"new_name\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.基础行操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选取指定行的数据\n",
    "df.iloc[3:10,]\n",
    "\n",
    "# 通过索引选取指定行的数据\n",
    "df.loc[\"index1\", \"index2\"]\n",
    "\n",
    "# 检索包含 \"关键字\" 的行\n",
    "df[df[\"species\"].isin([\"setosa\"])]\n",
    "\n",
    "# 根据条件筛选行\n",
    "df.query('sepal_length>=5') # 方法1\n",
    "df[df.sepal_length>= 5] # 方法2\n",
    "\n",
    "# 根据指定内容筛选出符合要求的行\n",
    "df[df[\"petal_length\"].isin([0.2, 0.3])]\n",
    "\n",
    "# 多条件筛选符合要求的行\n",
    "df[(df.sepal_length>1) & (df.species==\"setosa\") | (df.sepal_width<3)]\n",
    "\n",
    "# 丢弃某行\n",
    "df.drop(df.index[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.分组操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回根据字段\"species\"分组的对象\n",
    "df.groupby(\"species\")\n",
    "\n",
    "# 根据\"species\"分组，返回\"sepal_length\"的均值\n",
    "df[\"sepal_length\"].groupby(df[\"species\"]).mean()\n",
    "\n",
    "# 所有列根据字段\"species\"分组, 返回sum、mean和std的值 \n",
    "df.groupby(\"species\").agg([np.sum, np.mean, np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.关联操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge ##\n",
    "###########\n",
    "data = pd.merge(df1,df2,on='key',how='left') # right outer\n",
    "\n",
    "## concat ##\n",
    "############\n",
    "# 上下合并\n",
    "data = pd.concat([df1,df2])\n",
    "# 左右合并\n",
    "data = pd.concat([df1,df2],axis=1)\n",
    "\n",
    "## join ##\n",
    "##########\n",
    "data = df1.join(df2, how='left', lsuffix='_1', rsuffix='_2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
