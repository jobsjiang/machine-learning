{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spark 和 mapreduce有哪些区别，请用具体的例子说明？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MapReduce的缺陷\n",
    "#### 操作复杂\n",
    "开发起来：因为MapReduce只有map、reduce两种算子。\n",
    "1. low-level 低级别的。\n",
    "2. constrained\t有很多限制 （虽然可以使用一些类似Hive之类的框架来弥补）\n",
    "并且单元测试也很麻烦\n",
    "\n",
    "#### 计算效率低\n",
    "\n",
    "MapReduce是属于进程级别:MapTask ReduceTask,虽然有JVM复用，但还是效率不高\n",
    "\n",
    "频繁的IO: 因为MapReduce的作业一般都是串起来的作业，chain，一个作业的输出作为下一个作业的输入…并且作业的数据一般都会存储在HDFS上，这样会有频繁的磁盘和网络的IO。数据落地的话，是需要三个副本的。\n",
    "\n",
    "MapReduce的所有任务都需要序列化<br>\n",
    "排序：MapReduce每个场景都需要排序的，但是很多时候都是没有必要的<br>\n",
    "writable 要执行序列化的 read方法和wirte方法<br>\n",
    "writablecomparable 排序比较的<br>\n",
    "\n",
    "Memory:MapReduce基于内存做处理，但是是有限的<br>\n",
    "所以说MapReduce性能很低的，迭代次数比较多的话，性能会不好\n",
    "#### 不适合迭代处理\n",
    "数据挖掘，机器学习，图计算之类的，都需要很多迭代操作，所以不适合用MapReduce去做\n",
    "#### 不适合实时流式处理，只能离线处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark的特点\n",
    "1.spark的job输出结果可保存在内存中，而MapReduce的job输出结果只能保存在磁盘中，io读取速度要比内存中慢；\n",
    "\n",
    "2.spark以线程方式运行，MapReduce以进程的方式运行，进程要比线程耗费时间和资源；\n",
    "\n",
    "3.spark提供了更为丰富的算子操作；\n",
    "\n",
    "4.spark提供了更容易的api,支持python,java,scala;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rdd的本质是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDD，全称为Resilient Distributed Datasets，是一个容错的、并行的数据结构，可以让用户显式地将数据存储到磁盘和内存中，并能控制数据的分区。同时，RDD还提供了一组丰富的操作来操作这些数据。在这些操作中，诸如map、flatMap、filter等转换操作实现了monad模式，很好地契合了Scala的集合操作。除此之外，RDD还提供了诸如join、groupBy、reduceByKey等更为方便的操作（注意，reduceByKey是action，而非transformation），以支持常见的数据运算。\n",
    "通常来讲，针对数据处理有几种常见模型，包括：Iterative Algorithms，Relational Queries，MapReduce，Stream Processing。例如Hadoop MapReduce采用了MapReduces模型，Storm则采用了Stream Processing模型。RDD混合了这四种模型，使得Spark可以应用于各种大数据处理场景。\n",
    "RDD作为数据结构，本质上是一个只读的分区记录集合。一个RDD可以包含多个分区，每个分区就是一个dataset片段。RDD可以相互依赖。如果RDD的每个分区最多只能被一个Child RDD的一个分区使用，则称之为narrow dependency；若多个Child RDD分区都可以依赖，则称之为wide dependency。不同的操作依据其特性，可能会产生不同的依赖。例如map操作会产生narrow dependency，而join操作则产生wide dependency。<br>\n",
    "\n",
    "RDD本质上是一组数据的Spark表示，分布在多台机器上，使用API可以对其进行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
