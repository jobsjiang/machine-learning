{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row,functions\n",
    "from pyspark.ml.linalg import Vector,Vectors\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer,HashingTF, Tokenizer\n",
    "from pyspark.ml.classification import LogisticRegression,LogisticRegressionModel,BinaryLogisticRegressionSummary, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    rel = {}\n",
    "    rel['features'] = Vectors.dense(float(x[0]),float(x[1]),float(x[2]),float(x[3]))\n",
    "    rel['label'] = str(x[4])\n",
    "    return rel\n",
    "data = spark.sparkContext.textFile('../../../dataset/iris.txt').map(lambda line:line.split(',')).map(lambda p:Row(**f(p))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features', 'label']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n",
      "|         features|      label|\n",
      "+-----------------+-----------+\n",
      "|[5.1,3.5,1.4,0.2]|Iris-setosa|\n",
      "|[4.9,3.0,1.4,0.2]|Iris-setosa|\n",
      "|[4.7,3.2,1.3,0.2]|Iris-setosa|\n",
      "|[4.6,3.1,1.5,0.2]|Iris-setosa|\n",
      "|[5.0,3.6,1.4,0.2]|Iris-setosa|\n",
      "|[5.4,3.9,1.7,0.4]|Iris-setosa|\n",
      "|[4.6,3.4,1.4,0.3]|Iris-setosa|\n",
      "|[5.0,3.4,1.5,0.2]|Iris-setosa|\n",
      "|[4.4,2.9,1.4,0.2]|Iris-setosa|\n",
      "|[4.9,3.1,1.5,0.1]|Iris-setosa|\n",
      "|[5.4,3.7,1.5,0.2]|Iris-setosa|\n",
      "|[4.8,3.4,1.6,0.2]|Iris-setosa|\n",
      "|[4.8,3.0,1.4,0.1]|Iris-setosa|\n",
      "|[4.3,3.0,1.1,0.1]|Iris-setosa|\n",
      "|[5.8,4.0,1.2,0.2]|Iris-setosa|\n",
      "|[5.7,4.4,1.5,0.4]|Iris-setosa|\n",
      "|[5.4,3.9,1.3,0.4]|Iris-setosa|\n",
      "|[5.1,3.5,1.4,0.3]|Iris-setosa|\n",
      "|[5.7,3.8,1.7,0.3]|Iris-setosa|\n",
      "|[5.1,3.8,1.5,0.3]|Iris-setosa|\n",
      "+-----------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-versicolor:[7.0,3.2,4.7,1.4]\n",
      "Iris-versicolor:[6.4,3.2,4.5,1.5]\n",
      "Iris-versicolor:[6.9,3.1,4.9,1.5]\n",
      "Iris-versicolor:[5.5,2.3,4.0,1.3]\n",
      "Iris-versicolor:[6.5,2.8,4.6,1.5]\n",
      "Iris-versicolor:[5.7,2.8,4.5,1.3]\n",
      "Iris-versicolor:[6.3,3.3,4.7,1.6]\n",
      "Iris-versicolor:[4.9,2.4,3.3,1.0]\n",
      "Iris-versicolor:[6.6,2.9,4.6,1.3]\n",
      "Iris-versicolor:[5.2,2.7,3.9,1.4]\n",
      "Iris-versicolor:[5.0,2.0,3.5,1.0]\n",
      "Iris-versicolor:[5.9,3.0,4.2,1.5]\n",
      "Iris-versicolor:[6.0,2.2,4.0,1.0]\n",
      "Iris-versicolor:[6.1,2.9,4.7,1.4]\n",
      "Iris-versicolor:[5.6,2.9,3.6,1.3]\n",
      "Iris-versicolor:[6.7,3.1,4.4,1.4]\n",
      "Iris-versicolor:[5.6,3.0,4.5,1.5]\n",
      "Iris-versicolor:[5.8,2.7,4.1,1.0]\n",
      "Iris-versicolor:[6.2,2.2,4.5,1.5]\n",
      "Iris-versicolor:[5.6,2.5,3.9,1.1]\n",
      "Iris-versicolor:[5.9,3.2,4.8,1.8]\n",
      "Iris-versicolor:[6.1,2.8,4.0,1.3]\n",
      "Iris-versicolor:[6.3,2.5,4.9,1.5]\n",
      "Iris-versicolor:[6.1,2.8,4.7,1.2]\n",
      "Iris-versicolor:[6.4,2.9,4.3,1.3]\n",
      "Iris-versicolor:[6.6,3.0,4.4,1.4]\n",
      "Iris-versicolor:[6.8,2.8,4.8,1.4]\n",
      "Iris-versicolor:[6.7,3.0,5.0,1.7]\n",
      "Iris-versicolor:[6.0,2.9,4.5,1.5]\n",
      "Iris-versicolor:[5.7,2.6,3.5,1.0]\n",
      "Iris-versicolor:[5.5,2.4,3.8,1.1]\n",
      "Iris-versicolor:[5.5,2.4,3.7,1.0]\n",
      "Iris-versicolor:[5.8,2.7,3.9,1.2]\n",
      "Iris-versicolor:[6.0,2.7,5.1,1.6]\n",
      "Iris-versicolor:[5.4,3.0,4.5,1.5]\n",
      "Iris-versicolor:[6.0,3.4,4.5,1.6]\n",
      "Iris-versicolor:[6.7,3.1,4.7,1.5]\n",
      "Iris-versicolor:[6.3,2.3,4.4,1.3]\n",
      "Iris-versicolor:[5.6,3.0,4.1,1.3]\n",
      "Iris-versicolor:[5.5,2.5,4.0,1.3]\n",
      "Iris-versicolor:[5.5,2.6,4.4,1.2]\n",
      "Iris-versicolor:[6.1,3.0,4.6,1.4]\n",
      "Iris-versicolor:[5.8,2.6,4.0,1.2]\n",
      "Iris-versicolor:[5.0,2.3,3.3,1.0]\n",
      "Iris-versicolor:[5.6,2.7,4.2,1.3]\n",
      "Iris-versicolor:[5.7,3.0,4.2,1.2]\n",
      "Iris-versicolor:[5.7,2.9,4.2,1.3]\n",
      "Iris-versicolor:[6.2,2.9,4.3,1.3]\n",
      "Iris-versicolor:[5.1,2.5,3.0,1.1]\n",
      "Iris-versicolor:[5.7,2.8,4.1,1.3]\n",
      "Iris-virginica:[6.3,3.3,6.0,2.5]\n",
      "Iris-virginica:[5.8,2.7,5.1,1.9]\n",
      "Iris-virginica:[7.1,3.0,5.9,2.1]\n",
      "Iris-virginica:[6.3,2.9,5.6,1.8]\n",
      "Iris-virginica:[6.5,3.0,5.8,2.2]\n",
      "Iris-virginica:[7.6,3.0,6.6,2.1]\n",
      "Iris-virginica:[4.9,2.5,4.5,1.7]\n",
      "Iris-virginica:[7.3,2.9,6.3,1.8]\n",
      "Iris-virginica:[6.7,2.5,5.8,1.8]\n",
      "Iris-virginica:[7.2,3.6,6.1,2.5]\n",
      "Iris-virginica:[6.5,3.2,5.1,2.0]\n",
      "Iris-virginica:[6.4,2.7,5.3,1.9]\n",
      "Iris-virginica:[6.8,3.0,5.5,2.1]\n",
      "Iris-virginica:[5.7,2.5,5.0,2.0]\n",
      "Iris-virginica:[5.8,2.8,5.1,2.4]\n",
      "Iris-virginica:[6.4,3.2,5.3,2.3]\n",
      "Iris-virginica:[6.5,3.0,5.5,1.8]\n",
      "Iris-virginica:[7.7,3.8,6.7,2.2]\n",
      "Iris-virginica:[7.7,2.6,6.9,2.3]\n",
      "Iris-virginica:[6.0,2.2,5.0,1.5]\n",
      "Iris-virginica:[6.9,3.2,5.7,2.3]\n",
      "Iris-virginica:[5.6,2.8,4.9,2.0]\n",
      "Iris-virginica:[7.7,2.8,6.7,2.0]\n",
      "Iris-virginica:[6.3,2.7,4.9,1.8]\n",
      "Iris-virginica:[6.7,3.3,5.7,2.1]\n",
      "Iris-virginica:[7.2,3.2,6.0,1.8]\n",
      "Iris-virginica:[6.2,2.8,4.8,1.8]\n",
      "Iris-virginica:[6.1,3.0,4.9,1.8]\n",
      "Iris-virginica:[6.4,2.8,5.6,2.1]\n",
      "Iris-virginica:[7.2,3.0,5.8,1.6]\n",
      "Iris-virginica:[7.4,2.8,6.1,1.9]\n",
      "Iris-virginica:[7.9,3.8,6.4,2.0]\n",
      "Iris-virginica:[6.4,2.8,5.6,2.2]\n",
      "Iris-virginica:[6.3,2.8,5.1,1.5]\n",
      "Iris-virginica:[6.1,2.6,5.6,1.4]\n",
      "Iris-virginica:[7.7,3.0,6.1,2.3]\n",
      "Iris-virginica:[6.3,3.4,5.6,2.4]\n",
      "Iris-virginica:[6.4,3.1,5.5,1.8]\n",
      "Iris-virginica:[6.0,3.0,4.8,1.8]\n",
      "Iris-virginica:[6.9,3.1,5.4,2.1]\n",
      "Iris-virginica:[6.7,3.1,5.6,2.4]\n",
      "Iris-virginica:[6.9,3.1,5.1,2.3]\n",
      "Iris-virginica:[5.8,2.7,5.1,1.9]\n",
      "Iris-virginica:[6.8,3.2,5.9,2.3]\n",
      "Iris-virginica:[6.7,3.3,5.7,2.5]\n",
      "Iris-virginica:[6.7,3.0,5.2,2.3]\n",
      "Iris-virginica:[6.3,2.5,5.0,1.9]\n",
      "Iris-virginica:[6.5,3.0,5.2,2.0]\n",
      "Iris-virginica:[6.2,3.4,5.4,2.3]\n",
      "Iris-virginica:[5.9,3.0,5.1,1.8]\n"
     ]
    }
   ],
   "source": [
    "data.createOrReplaceTempView(\"iris\")\n",
    "df = spark.sql(\"select * from iris where label != 'Iris-setosa'\")\n",
    "rel = df.rdd.map(lambda t: str(t[1])+\":\"+str(t[0])).collect()\n",
    "for item in rel:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建ML的pipeline\n",
    "# 分别获取标签列和特征列，进行索引，并进行重命名\n",
    "labelIndexer = StringIndexer().setInputCol(\"label\").setOutputCol(\"indexedLabel\").fit(df)\n",
    "featureIndexer = VectorIndexer().setInputCol(\"features\").setOutputCol(\"indexedFeatures\").fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把数据集随机分成训练集和测试集，其中训练集占70%\n",
    "trainingData, testData = df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression parameters:\n",
      "aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0, current: 0.8)\n",
      "family: The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial (default: auto)\n",
      "featuresCol: features column name. (default: features, current: indexedFeatures)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label, current: indexedLabel)\n",
      "lowerBoundsOnCoefficients: The lower bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\n",
      "lowerBoundsOnIntercepts: The lower bounds on intercepts if fitting under bound constrained optimization. The bounds vector size must beequal with 1 for binomial regression, or the number oflasses for multinomial regression. (undefined)\n",
      "maxIter: max number of iterations (>= 0). (default: 100, current: 10)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0, current: 0.3)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "threshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p]. (default: 0.5)\n",
      "thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. (undefined)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
      "upperBoundsOnCoefficients: The upper bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\n",
      "upperBoundsOnIntercepts: The upper bounds on intercepts if fitting under bound constrained optimization. The bound vector size must be equal with 1 for binomial regression, or the number of classes for multinomial regression. (undefined)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().setLabelCol(\"indexedLabel\").setFeaturesCol(\"indexedFeatures\").setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "print(\"LogisticRegression parameters:\\n\" + lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置一个labelConverter,目的是把预测的类别重新转化成字符型的\n",
    "labelConverter = IndexToString().setInputCol(\"prediction\").setOutputCol(\n",
    "    \"predictedLabel\").setLabels(labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建pipeline，设置stage，然后调用fit()来训练模型\n",
    "lrPipeline =  Pipeline().setStages([labelIndexer, featureIndexer, lr, labelConverter])\n",
    "lrPipelineModel = lrPipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe本质是一个Estimator\n",
    "lrPredictions = lrPipelineModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-versicolor,[4.9,2.4,3.3,1.0]-->prob=[0.5331417041655584,0.4668582958344416],predictedLabelIris-versicolor\n",
      "Iris-versicolor,[5.0,2.0,3.5,1.0]-->prob=[0.5342324751823625,0.4657675248176375],predictedLabelIris-versicolor\n",
      "Iris-versicolor,[5.5,2.3,4.0,1.3]-->prob=[0.4874253258004515,0.5125746741995486],predictedLabelIris-virginica\n",
      "Iris-versicolor,[5.6,2.5,3.9,1.1]-->prob=[0.5233960991546126,0.4766039008453874],predictedLabelIris-versicolor\n",
      "Iris-versicolor,[5.6,2.9,3.6,1.3]-->prob=[0.4885204367105112,0.5114795632894888],predictedLabelIris-virginica\n",
      "Iris-versicolor,[5.8,2.7,4.1,1.0]-->prob=[0.5429459962392856,0.4570540037607143],predictedLabelIris-versicolor\n",
      "Iris-versicolor,[5.9,3.0,4.2,1.5]-->prob=[0.45701723109424275,0.5429827689057573],predictedLabelIris-virginica\n",
      "Iris-versicolor,[6.1,2.9,4.7,1.4]-->prob=[0.4765669358801282,0.5234330641198718],predictedLabelIris-virginica\n",
      "Iris-versicolor,[6.3,3.3,4.7,1.6]-->prob=[0.44408137042801027,0.5559186295719898],predictedLabelIris-virginica\n",
      "Iris-versicolor,[6.6,3.0,4.4,1.4]-->prob=[0.4820362187601351,0.5179637812398649],predictedLabelIris-virginica\n",
      "Iris-versicolor,[6.7,3.0,5.0,1.7]-->prob=[0.4312208740829725,0.5687791259170276],predictedLabelIris-virginica\n",
      "Iris-versicolor,[5.5,2.4,3.8,1.1]-->prob=[0.5223026425678602,0.47769735743213976],predictedLabelIris-versicolor\n",
      "Iris-virginica,[5.6,2.8,4.9,2.0]-->prob=[0.36947884665620756,0.6305211533437924],predictedLabelIris-virginica\n",
      "Iris-versicolor,[5.6,3.0,4.1,1.3]-->prob=[0.4885204367105112,0.5114795632894888],predictedLabelIris-virginica\n",
      "Iris-virginica,[5.7,2.5,5.0,2.0]-->prob=[0.3705005073684597,0.6294994926315404],predictedLabelIris-virginica\n",
      "Iris-versicolor,[5.7,2.6,3.5,1.0]-->prob=[0.5418581316455591,0.458141868354441],predictedLabelIris-versicolor\n",
      "Iris-versicolor,[5.7,2.9,4.2,1.3]-->prob=[0.48961565782632094,0.5103843421736791],predictedLabelIris-virginica\n",
      "Iris-versicolor,[5.7,3.0,4.2,1.2]-->prob=[0.5070610838786715,0.49293891612132845],predictedLabelIris-versicolor\n",
      "Iris-virginica,[5.8,2.7,5.1,1.9]-->prob=[0.3879594544037625,0.6120405455962376],predictedLabelIris-virginica\n",
      "Iris-versicolor,[6.0,2.7,5.1,1.6]-->prob=[0.4408376814334138,0.5591623185665863],predictedLabelIris-virginica\n",
      "Iris-versicolor,[6.1,3.0,4.6,1.4]-->prob=[0.4765669358801282,0.5234330641198718],predictedLabelIris-virginica\n",
      "Iris-virginica,[6.2,3.4,5.4,2.3]-->prob=[0.3279384492221753,0.6720615507778247],predictedLabelIris-virginica\n",
      "Iris-virginica,[6.3,2.5,5.0,1.9]-->prob=[0.39317568045031426,0.6068243195496857],predictedLabelIris-virginica\n",
      "Iris-virginica,[6.3,2.7,4.9,1.8]-->prob=[0.4099448827738568,0.5900551172261432],predictedLabelIris-virginica\n",
      "Iris-virginica,[6.3,3.3,6.0,2.5]-->prob=[0.29886256091683394,0.7011374390831661],predictedLabelIris-virginica\n",
      "Iris-virginica,[6.5,3.0,5.5,1.8]-->prob=[0.41206694379729025,0.5879330562027099],predictedLabelIris-virginica\n",
      "Iris-virginica,[6.5,3.0,5.8,2.2]-->prob=[0.3464715193780531,0.6535284806219469],predictedLabelIris-virginica\n",
      "Iris-virginica,[6.5,3.2,5.1,2.0]-->prob=[0.3787149031853957,0.6212850968146043],predictedLabelIris-virginica\n",
      "Iris-virginica,[6.7,3.1,5.6,2.4]-->prob=[0.31747531176835814,0.6825246882316418],predictedLabelIris-virginica\n",
      "Iris-virginica,[6.8,3.2,5.9,2.3]-->prob=[0.33376037554975985,0.6662396244502402],predictedLabelIris-virginica\n",
      "Iris-virginica,[7.3,2.9,6.3,1.8]-->prob=[0.4205871824129792,0.5794128175870208],predictedLabelIris-virginica\n",
      "Iris-virginica,[7.9,3.8,6.4,2.0]-->prob=[0.39325636133199243,0.6067436386680075],predictedLabelIris-virginica\n"
     ]
    }
   ],
   "source": [
    "preRel = lrPredictions.select(\n",
    "    \"predictedLabel\", \"label\", \"features\", \"probability\").collect()\n",
    "for item in preRel:\n",
    "    print(str(item['label'])+','+str(item['features'])+'-->prob=' +\n",
    "          str(item['probability'])+',predictedLabel'+str(item['predictedLabel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.37089743589743585\n"
     ]
    }
   ],
   "source": [
    "# 模型评估\n",
    "evaluator = MulticlassClassificationEvaluator().setLabelCol(\n",
    "    \"indexedLabel\").setPredictionCol(\"prediction\")\n",
    "lrAccuracy = evaluator.evaluate(lrPredictions)\n",
    "print(\"Test Error = \" + str(1.0 - lrAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.04382981417261569,0.0,0.0,0.0697895558410628]Intercept: 0.08200461572017557numClasses: 2numFeatures: 4\n"
     ]
    }
   ],
   "source": [
    "# model是一个PipelineModel,因此我们通过调用它的stages来获取模型\n",
    "lrModel = lrPipelineModel.stages[2]\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients)+\"Intercept: \"+str(lrModel.intercept) +\n",
    "      \"numClasses: \"+str(lrModel.numClasses)+\"numFeatures: \"+str(lrModel.numFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用多项逻辑斯蒂回归解决二分类问题\n",
    "#### 用多项逻辑斯蒂回归解决多分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
